{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detectron2 with DeepSort.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPsZAo4ET7jPMC9hR7AXgyI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stevearonson/VB-Video-Tracking/blob/master/Detectron2_with_DeepSort.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h3uyU7w5fcs",
        "colab_type": "text"
      },
      "source": [
        "## Install Detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_KwVIq_ZfCj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "21aaffcf-d843-4f2c-eda4-1c0867b5daaf"
      },
      "source": [
        "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
        "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "!pip install pyyaml==5.1 pycocotools>=2.0.1\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "# opencv is pre-installed on colab"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu101/torch_stable.html\n",
            "Requirement already up-to-date: torch==1.5 in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n",
            "Requirement already up-to-date: torchvision==0.6 in /usr/local/lib/python3.6/dist-packages (0.6.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6) (7.0.0)\n",
            "1.5.0+cu101 True\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET4YEyTZaHkx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "outputId": "6bf25bc9-f5ff-466c-f511-651840fb6f0b"
      },
      "source": [
        "!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html\n",
            "Requirement already satisfied: detectron2==0.1.3 in /usr/local/lib/python3.6/dist-packages (0.1.3+cu101)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (0.1.7)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (0.8.7)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (4.41.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (2.2.2)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (1.3.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (7.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (0.16.0)\n",
            "Requirement already satisfied: fvcore>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (0.1.1.post20200716)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (1.1.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (1.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (3.2.2)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.3) (4.0.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs>=0.1.6->detectron2==0.1.3) (5.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.7.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.30.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.18.5)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (0.34.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (3.12.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (0.9.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (1.17.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.3) (49.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot->detectron2==0.1.3) (2.4.7)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.1->detectron2==0.1.3) (1.7.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.3) (2.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (2.10)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.3) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.1.3) (1.7.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (4.1.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.3) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2==0.1.3) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpmjPcXmvJEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tqdm import tqdm \n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faDKnJes6Mjg",
        "colab_type": "text"
      },
      "source": [
        "## Access My Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15sYsmr7o21C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "fe964232-b7c6-4456-c5b1-fff7a20c5d26"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "base_dir = '/gdrive/My Drive/VB/Video'\n",
        "!ls '/gdrive/My Drive/VB/Video'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            " ball_tracker.mp4\t     court-diagram-vertical.jpg   people.mp4\n",
            " Cheshire_Halasz_Perin\t     demo.avi\t\t\t  player_pos.csv\n",
            " Cheshire_Halasz_Perin.pdf   image\t\t\t  tracker.mp4\n",
            " Cheshire_Halasz_Perin.zip  'MBVF M7 S3.mp4'\t\t  tracker_trails.jpg\n",
            " ckpt.t7\t\t     OpenCV.ipynb\t\t  video-clip.mp4\n",
            " court-diagram.jpg\t     panopt.mp4\t\t\t  voc2coco.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IhFURTO6Zq4",
        "colab_type": "text"
      },
      "source": [
        "##Install DeepSort"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-k2ARVYZspv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone --recurse-submodules https://github.com/sayef/detectron2-deepsort-pytorch.git\n",
        "!mv detectron2-deepsort-pytorch detectron2_deepsort_pytorch\n",
        "!cp '/gdrive/My Drive/VB/Video/ckpt.t7' detectron2_deepsort_pytorch/deep_sort/deep/checkpoint/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tqv1DC65yzB",
        "colab_type": "text"
      },
      "source": [
        "## Run the Detectron2-DeepSort Demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAVTZoVkpOJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd detectron2_deepsort_pytorch\n",
        "!python demo_detectron2_deepsort.py '/gdrive/My Drive/VB/Video/video-clip.mp4' --ignore_display\n",
        "!cp demo.avi '/gdrive/My Drive/VB/Video'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBOgXgQJRlW2",
        "colab_type": "text"
      },
      "source": [
        "# Combining Detectron2 with DeepSort\n",
        "\n",
        "Flow of video processing:\n",
        "\n",
        "1. Iterate over video frames\n",
        "2. Detect objects in frame\n",
        "3. Identify players (people) inside court playing area\n",
        "4. Move player detection data into deep sort data structure\n",
        "5. Update deepsort algorithm\n",
        "6. Draw bbox on original frame\n",
        "7. Map bbox to player location on court diagram\n",
        "8. Insert court diagram into original frame\n",
        "9. Write new frame to output video file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz-i90NPtVc4",
        "colab_type": "text"
      },
      "source": [
        "## Create a detection class using Detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCdpNNMP6ein",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from detectron2.utils.logger import setup_logger\n",
        "# setup_logger()\n",
        "\n",
        "import detectron2\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "\n",
        "\n",
        "class Detectron2:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.cfg = get_cfg()\n",
        "        self.cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "        self.cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "        self.cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "        self.predictor = DefaultPredictor(self.cfg)\n",
        "\n",
        "    def bbox(self, img):\n",
        "        rows = np.any(img, axis=1)\n",
        "        cols = np.any(img, axis=0)\n",
        "        rmin, rmax = np.where(rows)[0][[0, -1]]\n",
        "        cmin, cmax = np.where(cols)[0][[0, -1]]\n",
        "        return cmin, rmin, cmax, rmax\n",
        "\n",
        "    def detect(self, im):\n",
        "        outputs = self.predictor(im)\n",
        "        boxes = outputs[\"instances\"].pred_boxes.tensor.cpu().numpy()\n",
        "        classes = outputs[\"instances\"].pred_classes.cpu().numpy()\n",
        "        scores = outputs[\"instances\"].scores.cpu().numpy()\n",
        "\n",
        "        bbox_xcycwh, cls_conf, cls_ids = [], [], []\n",
        "\n",
        "        for (box, _class, score) in zip(boxes, classes, scores):\n",
        "\n",
        "            if _class == 0:\n",
        "                x0, y0, x1, y1 = box\n",
        "                bbox_xcycwh.append([(x1 + x0) / 2, (y1 + y0) / 2, (x1 - x0), (y1 - y0)])\n",
        "                cls_conf.append(score)\n",
        "                cls_ids.append(_class)\n",
        "\n",
        "        return np.array(bbox_xcycwh, dtype=np.float64), np.array(cls_conf), np.array(cls_ids)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fll4d8eEufJA",
        "colab_type": "text"
      },
      "source": [
        "## Create class for handling court geometries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTeqoPKRueF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from shapely.geometry import Point, Polygon\n",
        "\n",
        "class Court:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.video_court = np.array([[[467, 249], [781, 242], \n",
        "                                      [1274, 588], [630, 656], [3, 619]]])\n",
        "        self.video_playing = Polygon(np.array([[426, 235], [824, 230], \n",
        "                                               [1272, 512], [1253, 714], \n",
        "                                               [9, 713], [15, 470]]))\n",
        "        self.diagram_court = np.array([[[100, 100], [400, 100], [400, 700], \n",
        "                                        [250, 700], [100, 700]]])\n",
        "        self.M = cv2.findHomography(self.video_court, self.diagram_court)[0]\n",
        "\n",
        "        self.court_diagram_file = '/gdrive/My Drive/VB/Video/court-diagram-vertical.jpg'\n",
        "\n",
        "        # defaults for drawing on video frames\n",
        "        self.font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        self.fontScale = 1\n",
        "\n",
        "\n",
        "        self.radius = 10\n",
        "        self.color = [255, 0, 0]   \n",
        "        self.thickness = 2\n",
        "\n",
        "\n",
        "\n",
        "    def draw_court(self, frame):\n",
        "         return cv2.polylines(frame, [self.video_court], isClosed=True, \n",
        "                              color=self.color, thickness=self.thickness)\n",
        "\n",
        "\n",
        "    def in_playing_area(self, bbox_xcycwh):\n",
        "\n",
        "        xc, yc, w, h = bbox_xcycwh\n",
        "        player_pos = (xc, yc + h/2)\n",
        "        return Point(player_pos).within(self.video_playing)\n",
        "\n",
        "    def map_pos_to_diagram(self, player_positions):\n",
        "\n",
        "        src_pts = np.array([player_positions.astype('float32')])\n",
        "        dst_pts = cv2.perspectiveTransform(src_pts, self.M)\n",
        "        return dst_pts.squeeze().astype('int')\n",
        "\n",
        "    def create_mini_map(self, court_positions, identities):\n",
        "        # player marker parameters\n",
        "\n",
        "        court_diagram = cv2.imread(self.court_diagram_file)\n",
        "\n",
        "        for pt, tag in zip(court_positions, identities):\n",
        "            # cv2.circle(court_diagram, tuple(pt), self.radius, \n",
        "            #           self.color, self.thickness)\n",
        "            cv2.putText(court_diagram, str(tag), tuple(pt), self.font, self.fontScale, \n",
        "                        self.color, self.thickness, cv2.LINE_AA)\n",
        "\n",
        "\n",
        "        mini_map = cv2.resize(court_diagram, (250, 400), interpolation = cv2.INTER_AREA)\n",
        "\n",
        "        return mini_map\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvuWPmUbYPmR",
        "colab_type": "text"
      },
      "source": [
        "## Bounday Box Drawing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSkHiMW2YT4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "COLORS_10 =[(144,238,144),(178, 34, 34),(221,160,221),(  0,255,  0),(  0,128,  0),(210,105, 30),(220, 20, 60),\n",
        "            (192,192,192),(255,228,196),( 50,205, 50),(139,  0,139),(100,149,237),(138, 43,226),(238,130,238),\n",
        "            (255,  0,255),(  0,100,  0),(127,255,  0),(255,  0,255),(  0,  0,205),(255,140,  0),(255,239,213),\n",
        "            (199, 21,133),(124,252,  0),(147,112,219),(106, 90,205),(176,196,222),( 65,105,225),(173,255, 47),\n",
        "            (255, 20,147),(219,112,147),(186, 85,211),(199, 21,133),(148,  0,211),(255, 99, 71),(144,238,144),\n",
        "            (255,255,  0),(230,230,250),(  0,  0,255),(128,128,  0),(189,183,107),(255,255,224),(128,128,128),\n",
        "            (105,105,105),( 64,224,208),(205,133, 63),(  0,128,128),( 72,209,204),(139, 69, 19),(255,245,238),\n",
        "            (250,240,230),(152,251,152),(  0,255,255),(135,206,235),(  0,191,255),(176,224,230),(  0,250,154),\n",
        "            (245,255,250),(240,230,140),(245,222,179),(  0,139,139),(143,188,143),(255,  0,  0),(240,128,128),\n",
        "            (102,205,170),( 60,179,113),( 46,139, 87),(165, 42, 42),(178, 34, 34),(175,238,238),(255,248,220),\n",
        "            (218,165, 32),(255,250,240),(253,245,230),(244,164, 96),(210,105, 30)]\n",
        "\n",
        "def draw_bboxes(img, bbox, identities=None, offset=(0,0)):\n",
        "    for i,box,lbl in zip(range(len(identities)), bbox, identities):\n",
        "        x1,y1,x2,y2 = [int(i) for i in box]\n",
        "        x1 += offset[0]\n",
        "        x2 += offset[0]\n",
        "        y1 += offset[1]\n",
        "        y2 += offset[1]\n",
        "        # box text and bar\n",
        "        # id = int(identities[i]) if identities is not None else 0    \n",
        "        color = COLORS_10[i%len(COLORS_10)]\n",
        "        # label = '{}{}'.format(\"\", identities[i])\n",
        "        t_size = cv2.getTextSize(lbl, cv2.FONT_HERSHEY_PLAIN, 2 , 2)[0]\n",
        "        cv2.rectangle(img,(x1, y1),(x2,y2),color,3)\n",
        "        cv2.rectangle(img,(x1, y1),(x1+t_size[0]+3,y1+t_size[1]+4), color,-1)\n",
        "        cv2.putText(img,lbl,(x1,y1+t_size[1]+4), cv2.FONT_HERSHEY_PLAIN, 2, [255,255,255], 2)\n",
        "    return img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hn_NWcBZ0H3h",
        "colab_type": "text"
      },
      "source": [
        "## Main Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEm-KKcZ0zm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a time log for rallys in video\n",
        "time_log = pd.DataFrame({'Rally': [1,2,3,4], \n",
        "                         'Start': pd.to_timedelta(['00:00:11', '00:00:33', '00:00:52','00:01:18']),\n",
        "                         'Length': pd.to_timedelta(['00:00:06', '00:00:08', '00:00:14','00:00:11']),\n",
        "                         'P1' : ['Sophia', 'Emily', 'Emily', 'Emily'],\n",
        "                         'P2' : ['Emily', 'Maggie', 'Maggie', 'Maggie'],\n",
        "                         'P3' : ['Maggie', 'Taylor', 'Taylor', 'Taylor'],\n",
        "                         'P4' : ['Taylor', 'Quinn', 'Quinn', 'Quinn'],\n",
        "                         'P5' : ['Quinn', 'Cici', 'Cici', 'Cici'],\n",
        "                         'P6' : ['Cici', 'Sophia', 'Sophia', 'Sophia']\n",
        "                         })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8na2BFlS0Joe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import importlib  \n",
        "\n",
        "from detectron2_deepsort_pytorch.deep_sort import DeepSort\n",
        "from detectron2_deepsort_pytorch.util import draw_bboxes\n",
        "\n",
        "cap = cv2.VideoCapture('/gdrive/My Drive/VB/Video/MBVF M7 S3.mp4')\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "frames_per_second = cap.get(cv2.CAP_PROP_FPS)\n",
        "num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc('M', 'P', '4', 'V')\n",
        "videoOut = cv2.VideoWriter('/gdrive/My Drive/VB/Video/tracker.mp4', fourcc,\n",
        "                           frames_per_second, (width, height))\n",
        "\n",
        "detectron2 = Detectron2()\n",
        "# deepsort = DeepSort('detectron2_deepsort_pytorch/deep_sort/deep/checkpoint/ckpt.t7', use_cuda=True)\n",
        "court = Court()\n",
        "\n",
        "video_time = 0\n",
        "all_pos = []\n",
        "\n",
        "for _,rally in time_log.iterrows():\n",
        "\n",
        "    # skip to beginning of rally\n",
        "    skip_frames = int((rally['Start'].seconds - video_time) * frames_per_second)\n",
        "    for ix in range(skip_frames):\n",
        "        ret, frame = cap.read()\n",
        "        videoOut.write(frame)\n",
        "    video_time = rally['Start'].seconds\n",
        "\n",
        "\n",
        "    # process rally frames\n",
        "    # first_rally_frame = True\n",
        "    deepsort = DeepSort('detectron2_deepsort_pytorch/deep_sort/deep/checkpoint/ckpt.t7', use_cuda=True)\n",
        "\n",
        "    rally_frames = int(rally['Length'].seconds * frames_per_second)\n",
        "    for ix in tqdm(range(rally_frames)):\n",
        "        ret, frame = cap.read()\n",
        "        bbox_xcycwh, cls_conf, cls_ids = detectron2.detect(frame)\n",
        "\n",
        "        # add the court outline\n",
        "        frame_poly = court.draw_court(frame)\n",
        "\n",
        "        # find detection indicies of players\n",
        "        players_ix = [ix for ix, bbox in enumerate(bbox_xcycwh) if court.in_playing_area(bbox)]\n",
        "\n",
        "        # limit detections to players\n",
        "        player_xcycwh = bbox_xcycwh[players_ix, :]\n",
        "        # player_xcycwh[:, 3:] *= 1.2\n",
        "        player_conf = cls_conf[players_ix]\n",
        "\n",
        "        # update the deepsort model and collect tracker outputs\n",
        "        outputs = deepsort.update(player_xcycwh, player_conf, frame)\n",
        "        if len(outputs) > 0:\n",
        "            bbox_xyxy = outputs[:, :4]\n",
        "            identities = outputs[:, -1]\n",
        "\n",
        "            # if first_rally_frame:\n",
        "            #     first_rally_frame = False\n",
        "            #    our_players_ix = np.argsort(bbox_xyxy[:,3])[-5:]\n",
        "\n",
        "            # labels = identities.astype('str')\n",
        "            # labels[our_players_ix] = rally['P1':'P5'].values\n",
        "\n",
        "            frame_poly = draw_bboxes(frame_poly, bbox_xyxy, identities)\n",
        "\n",
        "            # create the min map\n",
        "            video_pos = np.array([[(x1+x2)/2, y2] for x1, y1, x2, y2 in bbox_xyxy])\n",
        "            diagram_pos = court.map_pos_to_diagram(video_pos)\n",
        "            miniMap = court.create_mini_map(diagram_pos, identities)\n",
        "\n",
        "            curr_pos = pd.DataFrame(np.concatenate([identities[:, None], diagram_pos], axis=1), \n",
        "                                    columns=['ID', 'X', 'Y'])\n",
        "            curr_pos.insert(0, 'Rally', rally['Rally'])\n",
        "            curr_pos.insert(1, 'Frame', ix)\n",
        "\n",
        "            all_pos.append(curr_pos)\n",
        "\n",
        "\n",
        "            #insert mini map into frame\n",
        "            (w,h,c) = miniMap.shape\n",
        "            frame_poly[0:w, 0:h, :] = miniMap\n",
        "\n",
        "        videoOut.write(frame_poly)\n",
        "\n",
        "    video_time += rally['Length'].seconds\n",
        "\n",
        "videoOut.release()\n",
        "cap.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn0rWQg0cm2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.concat(all_pos)\n",
        "df.to_csv('/gdrive/My Drive/VB/Video/player_pos.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQDk45ZafUOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "\n",
        "cmap = cm.get_cmap('Spectral')\n",
        "df[df['ID'].isin(['1', '2', '3', '4', '5'])].plot('X','Y',kind='scatter', c='ID', cmap=cmap, edgecolor=None)\n",
        "plt.gca().invert_yaxis()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XRffzCXvci4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.utils.video_visualizer import VideoVisualizer\n",
        "from detectron2.utils.visualizer import ColorMode, Visualizer\n",
        "\n",
        "import os"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LbQvee_vucz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(\"volleyball\", {}, base_dir + '/image/output.json', base_dir + '/image')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RWIWXDnwPV4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "fa5ad775-83f6-450f-eb64-5a25f744f85b"
      },
      "source": [
        "ball_metadata = MetadataCatalog.get(\"volleyball\")\n",
        "dataset_dicts = DatasetCatalog.get(\"volleyball\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1kSI_-uwbEl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e22428d7-0164-4e66-aca0-241181efe30c"
      },
      "source": [
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"volleyball\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")   # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 2000    # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ball)\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[07/27 22:07:43 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/27 22:07:43 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[07/27 22:07:43 d2.data.datasets.coco]: \u001b[0mLoaded 29 images in COCO format from /gdrive/My Drive/VB/Video/image/output.json\n",
            "\u001b[32m[07/27 22:07:43 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 29 images left.\n",
            "\u001b[32m[07/27 22:07:43 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
            "\u001b[36m|  category  | #instances   |\n",
            "|:----------:|:-------------|\n",
            "| volleyball | 29           |\n",
            "|            |              |\u001b[0m\n",
            "\u001b[32m[07/27 22:07:43 d2.data.common]: \u001b[0mSerializing 29 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/27 22:07:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[07/27 22:07:43 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[07/27 22:07:43 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[07/27 22:07:45 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[07/27 22:08:13 d2.utils.events]: \u001b[0m eta: 0:47:49  iter: 19  total_loss: 0.983  loss_cls: 0.706  loss_box_reg: 0.013  loss_rpn_cls: 0.233  loss_rpn_loc: 0.019  time: 1.4432  data_time: 0.0190  lr: 0.000005  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:08:42 d2.utils.events]: \u001b[0m eta: 0:47:39  iter: 39  total_loss: 0.934  loss_cls: 0.637  loss_box_reg: 0.004  loss_rpn_cls: 0.258  loss_rpn_loc: 0.027  time: 1.4410  data_time: 0.0061  lr: 0.000010  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:09:10 d2.utils.events]: \u001b[0m eta: 0:47:02  iter: 59  total_loss: 0.785  loss_cls: 0.522  loss_box_reg: 0.010  loss_rpn_cls: 0.237  loss_rpn_loc: 0.022  time: 1.4354  data_time: 0.0070  lr: 0.000015  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:09:39 d2.utils.events]: \u001b[0m eta: 0:46:36  iter: 79  total_loss: 0.692  loss_cls: 0.397  loss_box_reg: 0.014  loss_rpn_cls: 0.201  loss_rpn_loc: 0.018  time: 1.4349  data_time: 0.0057  lr: 0.000020  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:10:07 d2.utils.events]: \u001b[0m eta: 0:46:04  iter: 99  total_loss: 0.504  loss_cls: 0.284  loss_box_reg: 0.017  loss_rpn_cls: 0.162  loss_rpn_loc: 0.023  time: 1.4317  data_time: 0.0064  lr: 0.000025  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:10:36 d2.utils.events]: \u001b[0m eta: 0:45:17  iter: 119  total_loss: 0.427  loss_cls: 0.206  loss_box_reg: 0.017  loss_rpn_cls: 0.142  loss_rpn_loc: 0.029  time: 1.4291  data_time: 0.0066  lr: 0.000030  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:11:04 d2.utils.events]: \u001b[0m eta: 0:44:30  iter: 139  total_loss: 0.345  loss_cls: 0.163  loss_box_reg: 0.041  loss_rpn_cls: 0.106  loss_rpn_loc: 0.028  time: 1.4254  data_time: 0.0069  lr: 0.000035  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:11:32 d2.utils.events]: \u001b[0m eta: 0:43:49  iter: 159  total_loss: 0.317  loss_cls: 0.134  loss_box_reg: 0.058  loss_rpn_cls: 0.100  loss_rpn_loc: 0.022  time: 1.4223  data_time: 0.0064  lr: 0.000040  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:11:59 d2.utils.events]: \u001b[0m eta: 0:42:58  iter: 179  total_loss: 0.291  loss_cls: 0.121  loss_box_reg: 0.046  loss_rpn_cls: 0.080  loss_rpn_loc: 0.024  time: 1.4159  data_time: 0.0059  lr: 0.000045  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:12:28 d2.utils.events]: \u001b[0m eta: 0:42:52  iter: 199  total_loss: 0.302  loss_cls: 0.127  loss_box_reg: 0.078  loss_rpn_cls: 0.075  loss_rpn_loc: 0.019  time: 1.4201  data_time: 0.0064  lr: 0.000050  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:12:57 d2.utils.events]: \u001b[0m eta: 0:42:29  iter: 219  total_loss: 0.276  loss_cls: 0.108  loss_box_reg: 0.052  loss_rpn_cls: 0.070  loss_rpn_loc: 0.024  time: 1.4209  data_time: 0.0063  lr: 0.000055  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:13:26 d2.utils.events]: \u001b[0m eta: 0:42:07  iter: 239  total_loss: 0.248  loss_cls: 0.103  loss_box_reg: 0.049  loss_rpn_cls: 0.054  loss_rpn_loc: 0.022  time: 1.4226  data_time: 0.0058  lr: 0.000060  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:13:55 d2.utils.events]: \u001b[0m eta: 0:41:34  iter: 259  total_loss: 0.262  loss_cls: 0.104  loss_box_reg: 0.076  loss_rpn_cls: 0.047  loss_rpn_loc: 0.017  time: 1.4243  data_time: 0.0061  lr: 0.000065  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:14:23 d2.utils.events]: \u001b[0m eta: 0:41:09  iter: 279  total_loss: 0.291  loss_cls: 0.111  loss_box_reg: 0.087  loss_rpn_cls: 0.057  loss_rpn_loc: 0.016  time: 1.4244  data_time: 0.0065  lr: 0.000070  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:14:51 d2.utils.events]: \u001b[0m eta: 0:40:34  iter: 299  total_loss: 0.316  loss_cls: 0.128  loss_box_reg: 0.103  loss_rpn_cls: 0.046  loss_rpn_loc: 0.022  time: 1.4220  data_time: 0.0067  lr: 0.000075  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:15:20 d2.utils.events]: \u001b[0m eta: 0:40:17  iter: 319  total_loss: 0.286  loss_cls: 0.123  loss_box_reg: 0.099  loss_rpn_cls: 0.038  loss_rpn_loc: 0.023  time: 1.4231  data_time: 0.0061  lr: 0.000080  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:15:48 d2.utils.events]: \u001b[0m eta: 0:39:39  iter: 339  total_loss: 0.247  loss_cls: 0.110  loss_box_reg: 0.087  loss_rpn_cls: 0.034  loss_rpn_loc: 0.015  time: 1.4226  data_time: 0.0067  lr: 0.000085  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:16:17 d2.utils.events]: \u001b[0m eta: 0:39:10  iter: 359  total_loss: 0.288  loss_cls: 0.116  loss_box_reg: 0.098  loss_rpn_cls: 0.042  loss_rpn_loc: 0.017  time: 1.4224  data_time: 0.0064  lr: 0.000090  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:16:45 d2.utils.events]: \u001b[0m eta: 0:38:40  iter: 379  total_loss: 0.299  loss_cls: 0.106  loss_box_reg: 0.121  loss_rpn_cls: 0.036  loss_rpn_loc: 0.022  time: 1.4213  data_time: 0.0071  lr: 0.000095  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:17:13 d2.utils.events]: \u001b[0m eta: 0:38:11  iter: 399  total_loss: 0.279  loss_cls: 0.104  loss_box_reg: 0.094  loss_rpn_cls: 0.031  loss_rpn_loc: 0.016  time: 1.4204  data_time: 0.0060  lr: 0.000100  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:17:40 d2.utils.events]: \u001b[0m eta: 0:37:38  iter: 419  total_loss: 0.307  loss_cls: 0.103  loss_box_reg: 0.129  loss_rpn_cls: 0.030  loss_rpn_loc: 0.018  time: 1.4184  data_time: 0.0066  lr: 0.000105  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:18:09 d2.utils.events]: \u001b[0m eta: 0:37:09  iter: 439  total_loss: 0.253  loss_cls: 0.092  loss_box_reg: 0.107  loss_rpn_cls: 0.034  loss_rpn_loc: 0.019  time: 1.4182  data_time: 0.0059  lr: 0.000110  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:18:37 d2.utils.events]: \u001b[0m eta: 0:36:41  iter: 459  total_loss: 0.280  loss_cls: 0.093  loss_box_reg: 0.133  loss_rpn_cls: 0.026  loss_rpn_loc: 0.018  time: 1.4183  data_time: 0.0060  lr: 0.000115  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:19:05 d2.utils.events]: \u001b[0m eta: 0:36:11  iter: 479  total_loss: 0.277  loss_cls: 0.078  loss_box_reg: 0.128  loss_rpn_cls: 0.024  loss_rpn_loc: 0.017  time: 1.4176  data_time: 0.0059  lr: 0.000120  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:19:33 d2.utils.events]: \u001b[0m eta: 0:35:42  iter: 499  total_loss: 0.249  loss_cls: 0.081  loss_box_reg: 0.112  loss_rpn_cls: 0.027  loss_rpn_loc: 0.014  time: 1.4168  data_time: 0.0065  lr: 0.000125  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:20:02 d2.utils.events]: \u001b[0m eta: 0:35:14  iter: 519  total_loss: 0.278  loss_cls: 0.065  loss_box_reg: 0.150  loss_rpn_cls: 0.020  loss_rpn_loc: 0.017  time: 1.4174  data_time: 0.0062  lr: 0.000130  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:20:30 d2.utils.events]: \u001b[0m eta: 0:34:45  iter: 539  total_loss: 0.235  loss_cls: 0.064  loss_box_reg: 0.107  loss_rpn_cls: 0.020  loss_rpn_loc: 0.016  time: 1.4171  data_time: 0.0068  lr: 0.000135  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:20:58 d2.utils.events]: \u001b[0m eta: 0:34:15  iter: 559  total_loss: 0.247  loss_cls: 0.068  loss_box_reg: 0.131  loss_rpn_cls: 0.018  loss_rpn_loc: 0.016  time: 1.4169  data_time: 0.0061  lr: 0.000140  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:21:26 d2.utils.events]: \u001b[0m eta: 0:33:44  iter: 579  total_loss: 0.257  loss_cls: 0.066  loss_box_reg: 0.146  loss_rpn_cls: 0.018  loss_rpn_loc: 0.013  time: 1.4155  data_time: 0.0065  lr: 0.000145  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:21:54 d2.utils.events]: \u001b[0m eta: 0:33:16  iter: 599  total_loss: 0.297  loss_cls: 0.069  loss_box_reg: 0.177  loss_rpn_cls: 0.016  loss_rpn_loc: 0.011  time: 1.4156  data_time: 0.0063  lr: 0.000150  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:22:22 d2.utils.events]: \u001b[0m eta: 0:32:47  iter: 619  total_loss: 0.313  loss_cls: 0.064  loss_box_reg: 0.167  loss_rpn_cls: 0.026  loss_rpn_loc: 0.018  time: 1.4153  data_time: 0.0061  lr: 0.000155  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:22:50 d2.utils.events]: \u001b[0m eta: 0:32:16  iter: 639  total_loss: 0.236  loss_cls: 0.049  loss_box_reg: 0.135  loss_rpn_cls: 0.018  loss_rpn_loc: 0.014  time: 1.4152  data_time: 0.0058  lr: 0.000160  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:23:19 d2.utils.events]: \u001b[0m eta: 0:31:48  iter: 659  total_loss: 0.272  loss_cls: 0.062  loss_box_reg: 0.187  loss_rpn_cls: 0.019  loss_rpn_loc: 0.017  time: 1.4156  data_time: 0.0060  lr: 0.000165  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:23:48 d2.utils.events]: \u001b[0m eta: 0:31:22  iter: 679  total_loss: 0.254  loss_cls: 0.061  loss_box_reg: 0.148  loss_rpn_cls: 0.012  loss_rpn_loc: 0.016  time: 1.4161  data_time: 0.0063  lr: 0.000170  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:24:16 d2.utils.events]: \u001b[0m eta: 0:30:51  iter: 699  total_loss: 0.247  loss_cls: 0.052  loss_box_reg: 0.154  loss_rpn_cls: 0.014  loss_rpn_loc: 0.015  time: 1.4155  data_time: 0.0068  lr: 0.000175  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:24:44 d2.utils.events]: \u001b[0m eta: 0:30:25  iter: 719  total_loss: 0.251  loss_cls: 0.050  loss_box_reg: 0.158  loss_rpn_cls: 0.011  loss_rpn_loc: 0.014  time: 1.4159  data_time: 0.0060  lr: 0.000180  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:25:13 d2.utils.events]: \u001b[0m eta: 0:29:58  iter: 739  total_loss: 0.261  loss_cls: 0.046  loss_box_reg: 0.174  loss_rpn_cls: 0.009  loss_rpn_loc: 0.013  time: 1.4161  data_time: 0.0064  lr: 0.000185  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:25:41 d2.utils.events]: \u001b[0m eta: 0:29:27  iter: 759  total_loss: 0.261  loss_cls: 0.061  loss_box_reg: 0.165  loss_rpn_cls: 0.009  loss_rpn_loc: 0.015  time: 1.4155  data_time: 0.0058  lr: 0.000190  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:26:10 d2.utils.events]: \u001b[0m eta: 0:29:01  iter: 779  total_loss: 0.275  loss_cls: 0.058  loss_box_reg: 0.176  loss_rpn_cls: 0.013  loss_rpn_loc: 0.015  time: 1.4163  data_time: 0.0062  lr: 0.000195  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:26:38 d2.utils.events]: \u001b[0m eta: 0:28:34  iter: 799  total_loss: 0.214  loss_cls: 0.050  loss_box_reg: 0.137  loss_rpn_cls: 0.009  loss_rpn_loc: 0.012  time: 1.4166  data_time: 0.0067  lr: 0.000200  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:27:07 d2.utils.events]: \u001b[0m eta: 0:28:06  iter: 819  total_loss: 0.264  loss_cls: 0.055  loss_box_reg: 0.181  loss_rpn_cls: 0.007  loss_rpn_loc: 0.011  time: 1.4173  data_time: 0.0060  lr: 0.000205  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:27:35 d2.utils.events]: \u001b[0m eta: 0:27:35  iter: 839  total_loss: 0.262  loss_cls: 0.049  loss_box_reg: 0.168  loss_rpn_cls: 0.008  loss_rpn_loc: 0.015  time: 1.4170  data_time: 0.0058  lr: 0.000210  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:28:04 d2.utils.events]: \u001b[0m eta: 0:27:08  iter: 859  total_loss: 0.230  loss_cls: 0.051  loss_box_reg: 0.162  loss_rpn_cls: 0.006  loss_rpn_loc: 0.011  time: 1.4169  data_time: 0.0063  lr: 0.000215  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:28:32 d2.utils.events]: \u001b[0m eta: 0:26:39  iter: 879  total_loss: 0.229  loss_cls: 0.037  loss_box_reg: 0.162  loss_rpn_cls: 0.006  loss_rpn_loc: 0.011  time: 1.4173  data_time: 0.0062  lr: 0.000220  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:29:01 d2.utils.events]: \u001b[0m eta: 0:26:12  iter: 899  total_loss: 0.215  loss_cls: 0.044  loss_box_reg: 0.147  loss_rpn_cls: 0.004  loss_rpn_loc: 0.011  time: 1.4183  data_time: 0.0058  lr: 0.000225  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:29:30 d2.utils.events]: \u001b[0m eta: 0:25:45  iter: 919  total_loss: 0.248  loss_cls: 0.041  loss_box_reg: 0.178  loss_rpn_cls: 0.005  loss_rpn_loc: 0.014  time: 1.4190  data_time: 0.0063  lr: 0.000230  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:29:59 d2.utils.events]: \u001b[0m eta: 0:25:18  iter: 939  total_loss: 0.228  loss_cls: 0.046  loss_box_reg: 0.164  loss_rpn_cls: 0.005  loss_rpn_loc: 0.013  time: 1.4187  data_time: 0.0062  lr: 0.000235  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:30:27 d2.utils.events]: \u001b[0m eta: 0:24:48  iter: 959  total_loss: 0.215  loss_cls: 0.038  loss_box_reg: 0.164  loss_rpn_cls: 0.005  loss_rpn_loc: 0.011  time: 1.4185  data_time: 0.0066  lr: 0.000240  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:30:55 d2.utils.events]: \u001b[0m eta: 0:24:19  iter: 979  total_loss: 0.171  loss_cls: 0.028  loss_box_reg: 0.141  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 1.4186  data_time: 0.0063  lr: 0.000245  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:31:23 d2.utils.events]: \u001b[0m eta: 0:23:49  iter: 999  total_loss: 0.237  loss_cls: 0.040  loss_box_reg: 0.172  loss_rpn_cls: 0.005  loss_rpn_loc: 0.013  time: 1.4182  data_time: 0.0067  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:31:52 d2.utils.events]: \u001b[0m eta: 0:23:20  iter: 1019  total_loss: 0.190  loss_cls: 0.033  loss_box_reg: 0.131  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  time: 1.4181  data_time: 0.0081  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:32:20 d2.utils.events]: \u001b[0m eta: 0:22:51  iter: 1039  total_loss: 0.215  loss_cls: 0.035  loss_box_reg: 0.164  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  time: 1.4181  data_time: 0.0064  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:32:48 d2.utils.events]: \u001b[0m eta: 0:22:22  iter: 1059  total_loss: 0.201  loss_cls: 0.036  loss_box_reg: 0.153  loss_rpn_cls: 0.003  loss_rpn_loc: 0.011  time: 1.4180  data_time: 0.0062  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:33:16 d2.utils.events]: \u001b[0m eta: 0:21:52  iter: 1079  total_loss: 0.212  loss_cls: 0.033  loss_box_reg: 0.163  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.4178  data_time: 0.0065  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:33:45 d2.utils.events]: \u001b[0m eta: 0:21:24  iter: 1099  total_loss: 0.195  loss_cls: 0.028  loss_box_reg: 0.153  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 1.4180  data_time: 0.0064  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:34:14 d2.utils.events]: \u001b[0m eta: 0:20:57  iter: 1119  total_loss: 0.208  loss_cls: 0.026  loss_box_reg: 0.167  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 1.4183  data_time: 0.0065  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:34:42 d2.utils.events]: \u001b[0m eta: 0:20:28  iter: 1139  total_loss: 0.200  loss_cls: 0.028  loss_box_reg: 0.142  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 1.4183  data_time: 0.0061  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:35:11 d2.utils.events]: \u001b[0m eta: 0:20:02  iter: 1159  total_loss: 0.205  loss_cls: 0.031  loss_box_reg: 0.151  loss_rpn_cls: 0.003  loss_rpn_loc: 0.011  time: 1.4187  data_time: 0.0064  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:35:39 d2.utils.events]: \u001b[0m eta: 0:19:34  iter: 1179  total_loss: 0.204  loss_cls: 0.037  loss_box_reg: 0.160  loss_rpn_cls: 0.004  loss_rpn_loc: 0.012  time: 1.4185  data_time: 0.0063  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:36:06 d2.utils.events]: \u001b[0m eta: 0:19:04  iter: 1199  total_loss: 0.178  loss_cls: 0.026  loss_box_reg: 0.135  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 1.4177  data_time: 0.0068  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:36:35 d2.utils.events]: \u001b[0m eta: 0:18:36  iter: 1219  total_loss: 0.179  loss_cls: 0.030  loss_box_reg: 0.131  loss_rpn_cls: 0.004  loss_rpn_loc: 0.014  time: 1.4181  data_time: 0.0060  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:37:04 d2.utils.events]: \u001b[0m eta: 0:18:07  iter: 1239  total_loss: 0.165  loss_cls: 0.028  loss_box_reg: 0.118  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 1.4187  data_time: 0.0067  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:37:34 d2.utils.events]: \u001b[0m eta: 0:17:40  iter: 1259  total_loss: 0.196  loss_cls: 0.030  loss_box_reg: 0.147  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.4192  data_time: 0.0067  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:38:02 d2.utils.events]: \u001b[0m eta: 0:17:11  iter: 1279  total_loss: 0.181  loss_cls: 0.026  loss_box_reg: 0.139  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  time: 1.4195  data_time: 0.0070  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:38:31 d2.utils.events]: \u001b[0m eta: 0:16:43  iter: 1299  total_loss: 0.192  loss_cls: 0.025  loss_box_reg: 0.142  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 1.4198  data_time: 0.0065  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:39:00 d2.utils.events]: \u001b[0m eta: 0:16:15  iter: 1319  total_loss: 0.156  loss_cls: 0.024  loss_box_reg: 0.122  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 1.4204  data_time: 0.0063  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:39:28 d2.utils.events]: \u001b[0m eta: 0:15:47  iter: 1339  total_loss: 0.176  loss_cls: 0.024  loss_box_reg: 0.134  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 1.4198  data_time: 0.0062  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:39:57 d2.utils.events]: \u001b[0m eta: 0:15:18  iter: 1359  total_loss: 0.160  loss_cls: 0.025  loss_box_reg: 0.110  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 1.4201  data_time: 0.0064  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:40:24 d2.utils.events]: \u001b[0m eta: 0:14:49  iter: 1379  total_loss: 0.187  loss_cls: 0.025  loss_box_reg: 0.146  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 1.4196  data_time: 0.0065  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:40:53 d2.utils.events]: \u001b[0m eta: 0:14:21  iter: 1399  total_loss: 0.154  loss_cls: 0.023  loss_box_reg: 0.123  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 1.4197  data_time: 0.0064  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:41:22 d2.utils.events]: \u001b[0m eta: 0:13:53  iter: 1419  total_loss: 0.173  loss_cls: 0.023  loss_box_reg: 0.127  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 1.4198  data_time: 0.0063  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:41:50 d2.utils.events]: \u001b[0m eta: 0:13:25  iter: 1439  total_loss: 0.175  loss_cls: 0.023  loss_box_reg: 0.138  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 1.4199  data_time: 0.0061  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:42:18 d2.utils.events]: \u001b[0m eta: 0:12:56  iter: 1459  total_loss: 0.159  loss_cls: 0.020  loss_box_reg: 0.119  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  time: 1.4197  data_time: 0.0063  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:42:47 d2.utils.events]: \u001b[0m eta: 0:12:27  iter: 1479  total_loss: 0.175  loss_cls: 0.030  loss_box_reg: 0.130  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 1.4199  data_time: 0.0065  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:43:15 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 1499  total_loss: 0.165  loss_cls: 0.024  loss_box_reg: 0.119  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 1.4198  data_time: 0.0065  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:43:43 d2.utils.events]: \u001b[0m eta: 0:11:30  iter: 1519  total_loss: 0.165  loss_cls: 0.026  loss_box_reg: 0.120  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 1.4196  data_time: 0.0065  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:44:12 d2.utils.events]: \u001b[0m eta: 0:11:02  iter: 1539  total_loss: 0.182  loss_cls: 0.028  loss_box_reg: 0.142  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  time: 1.4196  data_time: 0.0060  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:44:40 d2.utils.events]: \u001b[0m eta: 0:10:33  iter: 1559  total_loss: 0.144  loss_cls: 0.027  loss_box_reg: 0.113  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 1.4197  data_time: 0.0058  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:45:08 d2.utils.events]: \u001b[0m eta: 0:10:04  iter: 1579  total_loss: 0.152  loss_cls: 0.022  loss_box_reg: 0.120  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 1.4195  data_time: 0.0062  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:45:38 d2.utils.events]: \u001b[0m eta: 0:09:36  iter: 1599  total_loss: 0.154  loss_cls: 0.024  loss_box_reg: 0.122  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 1.4200  data_time: 0.0061  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:46:06 d2.utils.events]: \u001b[0m eta: 0:09:07  iter: 1619  total_loss: 0.161  loss_cls: 0.020  loss_box_reg: 0.124  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 1.4200  data_time: 0.0060  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:46:34 d2.utils.events]: \u001b[0m eta: 0:08:39  iter: 1639  total_loss: 0.160  loss_cls: 0.023  loss_box_reg: 0.120  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 1.4196  data_time: 0.0062  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:47:03 d2.utils.events]: \u001b[0m eta: 0:08:11  iter: 1659  total_loss: 0.151  loss_cls: 0.021  loss_box_reg: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.4201  data_time: 0.0064  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:47:33 d2.utils.events]: \u001b[0m eta: 0:07:42  iter: 1679  total_loss: 0.143  loss_cls: 0.026  loss_box_reg: 0.104  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.4208  data_time: 0.0064  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:48:00 d2.utils.events]: \u001b[0m eta: 0:07:14  iter: 1699  total_loss: 0.134  loss_cls: 0.022  loss_box_reg: 0.099  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 1.4204  data_time: 0.0066  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:48:29 d2.utils.events]: \u001b[0m eta: 0:06:44  iter: 1719  total_loss: 0.149  loss_cls: 0.023  loss_box_reg: 0.111  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 1.4205  data_time: 0.0063  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:48:57 d2.utils.events]: \u001b[0m eta: 0:06:15  iter: 1739  total_loss: 0.170  loss_cls: 0.024  loss_box_reg: 0.123  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  time: 1.4203  data_time: 0.0063  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:49:26 d2.utils.events]: \u001b[0m eta: 0:05:47  iter: 1759  total_loss: 0.139  loss_cls: 0.018  loss_box_reg: 0.106  loss_rpn_cls: 0.000  loss_rpn_loc: 0.011  time: 1.4207  data_time: 0.0058  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:49:55 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 1779  total_loss: 0.131  loss_cls: 0.021  loss_box_reg: 0.100  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.4208  data_time: 0.0064  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:50:22 d2.utils.events]: \u001b[0m eta: 0:04:49  iter: 1799  total_loss: 0.147  loss_cls: 0.024  loss_box_reg: 0.114  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 1.4204  data_time: 0.0058  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:50:51 d2.utils.events]: \u001b[0m eta: 0:04:20  iter: 1819  total_loss: 0.136  loss_cls: 0.017  loss_box_reg: 0.097  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 1.4205  data_time: 0.0064  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:51:20 d2.utils.events]: \u001b[0m eta: 0:03:51  iter: 1839  total_loss: 0.147  loss_cls: 0.022  loss_box_reg: 0.114  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.4206  data_time: 0.0060  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:51:48 d2.utils.events]: \u001b[0m eta: 0:03:23  iter: 1859  total_loss: 0.147  loss_cls: 0.024  loss_box_reg: 0.119  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 1.4207  data_time: 0.0063  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:52:16 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 1879  total_loss: 0.134  loss_cls: 0.016  loss_box_reg: 0.099  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 1.4205  data_time: 0.0069  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:52:44 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 1899  total_loss: 0.151  loss_cls: 0.027  loss_box_reg: 0.114  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 1.4203  data_time: 0.0064  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:53:13 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 1919  total_loss: 0.148  loss_cls: 0.018  loss_box_reg: 0.115  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 1.4203  data_time: 0.0055  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:53:42 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 1939  total_loss: 0.137  loss_cls: 0.021  loss_box_reg: 0.112  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.4205  data_time: 0.0062  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:54:10 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 1959  total_loss: 0.124  loss_cls: 0.017  loss_box_reg: 0.100  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  time: 1.4203  data_time: 0.0064  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:54:38 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 1979  total_loss: 0.126  loss_cls: 0.022  loss_box_reg: 0.091  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.4204  data_time: 0.0063  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:55:07 d2.utils.events]: \u001b[0m eta: 0:00:01  iter: 1999  total_loss: 0.128  loss_cls: 0.016  loss_box_reg: 0.102  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  time: 1.4199  data_time: 0.0060  lr: 0.000250  max_mem: 2802M\n",
            "\u001b[32m[07/27 22:55:08 d2.engine.hooks]: \u001b[0mOverall training speed: 1997 iterations in 0:47:17 (1.4206 s / it)\n",
            "\u001b[32m[07/27 22:55:08 d2.engine.hooks]: \u001b[0mTotal training time: 0:47:20 (0:00:03 on hooks)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM8k0oKdyjNV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "626f7df5-aa83-40e7-8b9e-db997913b779"
      },
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold for this model\n",
        "cfg.DATASETS.TRAIN = (\"volleyball\",)\n",
        "cfg.DATASETS.TEST = (\"volleyball\", )\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (2, 1024) in the checkpoint but (81, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (2,) in the checkpoint but (81,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (4, 1024) in the checkpoint but (320, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (4,) in the checkpoint but (320,) in the model! You might want to double check if this is expected.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu7sDFkbyuq8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5e187d7-e535-4327-938f-baabc91e8403"
      },
      "source": [
        "\n",
        "cap = cv2.VideoCapture(base_dir + '/MBVF M7 S3.mp4')\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "frames_per_second = cap.get(cv2.CAP_PROP_FPS)\n",
        "num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc('M', 'P', '4', 'V')\n",
        "videoOut = cv2.VideoWriter(base_dir + '/ball_tracker.mp4', fourcc,\n",
        "                           frames_per_second, (width, height))\n",
        "\n",
        "v = VideoVisualizer(ball_metadata, ColorMode.IMAGE)\n",
        "all_ball_pos = []\n",
        "for ix in tqdm(range(int(15 * frames_per_second))):\n",
        "    ret, frame = cap.read()\n",
        "    outputs = predictor(frame)\n",
        "\n",
        "    pred_boxes = outputs[\"instances\"].get('pred_boxes')\n",
        "    if pred_boxes is None:\n",
        "        pred_boxes = []\n",
        "\n",
        "    ball_pos = []\n",
        "    for box_ix, box in enumerate(pred_boxes):\n",
        "        xcenter = int((box[0] + box[2]) / 2)\n",
        "        ycenter = int(box[1] + box[3])\n",
        "        ball_pos.append({'Frame' : ix, 'ID' : box_ix, 'X': xcenter, 'Y' : ycenter})\n",
        "\n",
        "    all_ball_pos.extend(ball_pos)\n",
        "\n",
        "    out = v.draw_instance_predictions(frame, outputs[\"instances\"].to(\"cpu\")).get_image()\n",
        "    videoOut.write(out)\n",
        "\n",
        "videoOut.release()\n",
        "cap.release()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 421/421 [03:13<00:00,  2.17it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4rR_vICR-69",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "d08fe8dd-2a13-4b01-ca86-1c312ae24836"
      },
      "source": [
        "!ls -ls output"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 322352\n",
            "    16 -rw-r--r-- 1 root root     12829 Jul 27 19:39 events.out.tfevents.1595878347.295bff8010e2.125.0\n",
            "    48 -rw-r--r-- 1 root root     42894 Jul 27 20:56 events.out.tfevents.1595881934.295bff8010e2.125.1\n",
            "     4 -rw-r--r-- 1 root root        15 Jul 27 20:56 last_checkpoint\n",
            "    40 -rw-r--r-- 1 root root     36564 Jul 27 20:56 metrics.json\n",
            "322244 -rw-r--r-- 1 root root 329977388 Jul 27 20:56 model_final.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNrEE5QB3g87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for d in random.sample(dataset_dicts, 3):\n",
        "   img = cv2.imread(d[\"file_name\"])\n",
        "   visualizer = Visualizer(img[:, :, ::-1], metadata=ball_metadata,    scale=0.5)\n",
        "   out = visualizer.draw_dataset_dict(d)\n",
        "   cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkqjDHJg9lWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im = cv2.imread(base_dir + '/image/2.png')\n",
        "outputs = predictor(im)\n",
        "v = Visualizer(im[:, :, ::-1],\n",
        "  metadata=ball_metadata,\n",
        "  scale=1)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}